![Screenshot](static/images/demo.png)

ğŸŒŸ Best ideas come when you least expect themâ€¦

1ï¸âƒ£ Fever knocked me down for days. ğŸ¤’
2ï¸âƒ£ While resting, I thought: Why not play with LLMs?
3ï¸âƒ£ So I turned downtime into build time.

âœ… What I made:

Local AI chatbot

FastAPI backend

Ollama + Gemma3 for LLM

Gradio for a real-time chat UI

Streams responses & keeps session history

Runs fully local in one Python file

ğŸš€ How to run:

bash
Copy
Edit
uvicorn chatbot_api:app --reload
Then chat at: http://127.0.0.1:8000/gradio

ğŸ’¡ Why I love it:

Local LLMs = no cloud, no cost

Easy to learn, fun to build

Proof that learning never stops â€” even sick in bed!

ğŸ”— Want the code? Comment â€œğŸ”—â€ â€” Iâ€™ll share!

ğŸ‘‡ Built your own local LLM? Tell me about it!

#LLM #FastAPI #Gemma3 #Ollama #Gradio #Python #AI #OpenSource
