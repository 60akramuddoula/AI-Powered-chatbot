![Screenshot](static/images/demo.png)

🌟 Best ideas come when you least expect them…

1️⃣ Fever knocked me down for days. 🤒
2️⃣ While resting, I thought: Why not play with LLMs?
3️⃣ So I turned downtime into build time.

✅ What I made:

Local AI chatbot

FastAPI backend

Ollama + Gemma3 for LLM

Gradio for a real-time chat UI

Streams responses & keeps session history

Runs fully local in one Python file

🚀 How to run:

bash
Copy
Edit
uvicorn chatbot_api:app --reload
Then chat at: http://127.0.0.1:8000/gradio

💡 Why I love it:

Local LLMs = no cloud, no cost

Easy to learn, fun to build

Proof that learning never stops — even sick in bed!

🔗 Want the code? Comment “🔗” — I’ll share!

👇 Built your own local LLM? Tell me about it!

#LLM #FastAPI #Gemma3 #Ollama #Gradio #Python #AI #OpenSource
